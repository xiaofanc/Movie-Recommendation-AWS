{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col, isnan, when, count, trim\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.functions import countDistinct, explode, split, concat_ws, collect_list\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, DoubleType as Dbl, StringType as Str, IntegerType as Int, DateType as Date\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# STEP 1: Get the params of the created redshift cluster \n",
    "- We need:\n",
    "    - The redshift cluster <font color='red'>endpoint</font>\n",
    "    - The <font color='red'>IAM role ARN</font> that give access to Redshift to read from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "#Normally this file should be in ~/.aws/credentials\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['KEY']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# FILL IN THE REDSHIFT ENPOINT HERE\n",
    "# e.g. DWH_ENDPOINT=\"redshift-cluster-1.csmamz5zxmle.us-west-2.redshift.amazonaws.com\" \n",
    "DWH_ENDPOINT=\"dwhcluster.ci2m6m74tbzm.us-west-2.redshift.amazonaws.com\" \n",
    "    \n",
    "#FILL IN THE IAM ROLE ARN you got in step 2.2 of the previous exercise\n",
    "#e.g DWH_ROLE_ARN=\"arn:aws:iam::988332130976:role/dwhRole\"\n",
    "DWH_ROLE_ARN=\"arn:aws:iam::264680862608:role/dwhRole\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Part 1: Load Data from S3 and clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "movieSchema = R([\n",
    "            Fld(\"movieId\",Int()),\n",
    "            Fld(\"title\",Str()),\n",
    "            Fld(\"genres\",Str())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ratingSchema = R([\n",
    "            Fld(\"userId\",Int()),\n",
    "            Fld(\"movieId\",Int()),\n",
    "            Fld(\"rating\",Dbl()),\n",
    "            Fld(\"ts\",Str())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagSchema = R([\n",
    "            Fld(\"userId\",Int()),\n",
    "            Fld(\"movieId\",Int()),\n",
    "            Fld(\"tag\",Str()),\n",
    "            Fld(\"ts\",Str())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read movies, ratings, and tags csv\n",
    "dfmovies = spark.read.csv(\"s3a://udacity-input/ml-latest-small/movies.csv\", header=True, schema=movieSchema)\n",
    "dfratings = spark.read.csv(\"s3a://udacity-input/ml-latest-small/ratings.csv\", header = True, schema=ratingSchema)\n",
    "dftags = spark.read.csv(\"s3a://udacity-input/ml-latest-small/tags.csv\", header = True, schema=tagSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+--------+----------+-----------+\n",
      "|Film                                                    |Year    |Awards    |Nominations|\n",
      "+--------------------------------------------------------+--------+----------+-----------+\n",
      "|Parasite                                                |2019    |4.0       |6.0        |\n",
      "|Ford v Ferrari                                          |2019    |2.0       |4.0        |\n",
      "|Learning to Skateboard in a Warzone (If You're a Girl)  |2019    |1.0       |1.0        |\n",
      "|The Neighbors' Window                                   |2019    |1.0       |1.0        |\n",
      "|Little Women                                            |2019    |1.0       |6.0        |\n",
      "|Marriage Story                                          |2019    |1.0       |6.0        |\n",
      "|Jojo Rabbit                                             |2019    |1.0       |6.0        |\n",
      "|Toy Story 4                                             |2019    |1.0       |2.0        |\n",
      "|Joker   2019                                            |2       |1.0       |1.0        |\n",
      "|Once Upon a Time in Hollywood   2019                    |2       |1.0       |0.0        |\n",
      "+--------------------------------------------------------+--------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read awards txt\n",
    "dfawards = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3a://udacity-input/ml-latest-small/Awards.txt\")\n",
    "\n",
    "dfawards.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+-----------+\n",
      "|Film                |Year   |Awards    |Nominations|\n",
      "+--------------------+-------+----------+-----------+\n",
      "|Becket              |1964.0 |1.0       |12         |\n",
      "|Ben-Hur             |1959.0 |11.0      |12         |\n",
      "|Dances with Wolves  |1990.0 |7.0       |12         |\n",
      "|The English Patient |1996.0 |9.0       |12         |\n",
      "|Gladiator           |2000.0 |5.0       |12         |\n",
      "|Johnny Belinda      |1948.0 |1.0       |12         |\n",
      "|Lincoln             |2012.0 |2.0       |12         |\n",
      "|Mrs. Miniver        |1942.0 |6.0       |12         |\n",
      "|My Fair Lady        |1964.0 |8.0       |12         |\n",
      "|On the Waterfront   |1954.0 |8.0       |12         |\n",
      "+--------------------+-------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read award_corrected txt\n",
    "dfawards2 = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3a://udacity-input/ml-latest-small/Award_corrected.txt\")\n",
    "\n",
    "dfawards2.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|movieId|title                             |genres                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmovies.printSchema()\n",
    "dfmovies.show(5, truncate = False)\n",
    "dfmovies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfratings = dfratings.withColumn(\n",
    "    \"rate_time\",\n",
    "    F.to_timestamp(F.from_unixtime((col(\"ts\") / 1000) , 'yyyy-MM-dd HH:mm:ss.SSS')).cast(\"Timestamp\")\n",
    ").drop(\"ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- rate_time: timestamp (nullable = true)\n",
      "\n",
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          rate_time|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      1|   4.0|1970-01-12 04:03:02|\n",
      "|     1|      3|   4.0|1970-01-12 04:03:01|\n",
      "|     1|      6|   4.0|1970-01-12 04:03:02|\n",
      "|     1|     47|   5.0|1970-01-12 04:03:03|\n",
      "|     1|     50|   5.0|1970-01-12 04:03:02|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfratings.printSchema()\n",
    "dfratings.show(5)\n",
    "dfratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dftags = dftags.withColumn(\"tag_time\", F.to_timestamp(col(\"ts\") / 1000)).drop(\"ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- tag_time: timestamp (nullable = true)\n",
      "\n",
      "+------+-------+---------------+--------------------+\n",
      "|userId|movieId|            tag|            tag_time|\n",
      "+------+-------+---------------+--------------------+\n",
      "|     2|  60756|          funny|1970-01-17 17:35:...|\n",
      "|     2|  60756|Highly quotable|1970-01-17 17:35:...|\n",
      "|     2|  60756|   will ferrell|1970-01-17 17:35:...|\n",
      "|     2|  89774|   Boxing story|1970-01-17 17:35:...|\n",
      "|     2|  89774|            MMA|1970-01-17 17:35:...|\n",
      "+------+-------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3683"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftags.printSchema()\n",
    "dftags.show(5)\n",
    "dftags.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Film   ', 'Year   ', 'Awards    ', 'Nominations']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfawards = dfawards.withColumn(\"title\", dfawards['Film   '].cast(Str())).drop('Film   ')\n",
    "dfawards = dfawards.withColumn(\"year\", dfawards['Year   '].cast(Date())).drop(\"Year   \")\n",
    "dfawards = dfawards.withColumn(\"awards\", dfawards['Awards    '].cast(Dbl())).drop(\"Awards    \")\n",
    "dfawards = dfawards.withColumn(\"nominations\", dfawards['Nominations'].cast(Int()))\n",
    "dfawards = dfawards.withColumn(\"year\", F.year(\"year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Film   ', 'Year   ', 'Awards    ', 'Nominations']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfawards2 = dfawards2.withColumn(\"title\", dfawards2['Film   '].cast(Str())).drop('Film   ')\n",
    "dfawards2 = dfawards2.withColumn(\"awards\", dfawards2['Awards    '].cast(Dbl())).drop(\"Awards    \")\n",
    "dfawards2 = dfawards2.withColumn(\"nominations\", dfawards2['Nominations'].cast(Int()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfawards2 = dfawards2.withColumn(\"date\", F.to_timestamp(col('Year   '))).drop('Year   ')\n",
    "dfawards2 = dfawards2.withColumn(\"year\", F.year(\"date\")).drop(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nominations: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- awards: double (nullable = true)\n",
      "\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|nominations|title                                                   |year|awards|\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|6          |Parasite                                                |2019|4.0   |\n",
      "|4          |Ford v Ferrari                                          |2019|2.0   |\n",
      "|1          |Learning to Skateboard in a Warzone (If You're a Girl)  |2019|1.0   |\n",
      "|1          |The Neighbors' Window                                   |2019|1.0   |\n",
      "|6          |Little Women                                            |2019|1.0   |\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1316"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards.printSchema()\n",
    "dfawards.show(5, truncate = False)\n",
    "dfawards.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nominations: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- awards: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "+-----------+--------------------+------+----+\n",
      "|nominations|title               |awards|year|\n",
      "+-----------+--------------------+------+----+\n",
      "|12         |Becket              |1.0   |1970|\n",
      "|12         |Ben-Hur             |11.0  |1970|\n",
      "|12         |Dances with Wolves  |7.0   |1970|\n",
      "|12         |The English Patient |9.0   |1970|\n",
      "|12         |Gladiator           |5.0   |1970|\n",
      "+-----------+--------------------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards2.printSchema()\n",
    "dfawards2.show(5, truncate = False)\n",
    "dfawards2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to S3\n",
    "dfawards.write.parquet(\"s3a://sparkifytest/movies/awards/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfawards2.write.parquet(\"s3a://sparkifytest/movies/awards2/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfmovies.write.parquet(\"s3a://sparkifytest/movies/movies/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfratings.write.parquet(\"s3a://sparkifytest/movies/ratings/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dftags.write.parquet(\"s3a://sparkifytest/movies/tags/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfawards = spark.read.parquet(\"s3a://sparkifytest/movies/awards/*\")\n",
    "dfawards2 = spark.read.parquet(\"s3a://sparkifytest/movies/awards2/*\")\n",
    "dfmovies = spark.read.parquet(\"s3a://sparkifytest/movies/movies/*\")\n",
    "dfratings = spark.read.parquet(\"s3a://sparkifytest/movies/ratings/*\")\n",
    "dftags = spark.read.parquet(\"s3a://sparkifytest/movies/tags/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Part 2: Explore the Data and data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Wrangling with DataFrames\n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|movieId|title|genres|\n",
      "+-------+-----+------+\n",
      "|      0|    0|     0|\n",
      "+-------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "dfmovies.select([count(when(col(c).isNull(), c)).alias(c) for c in dfmovies.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|rate_time|\n",
      "+------+-------+------+---------+\n",
      "|     0|      0|     0|        0|\n",
      "+------+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfratings.select([count(when(col(c).isNull(), c)).alias(c) for c in dfratings.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+----+------+\n",
      "|nominations|title|year|awards|\n",
      "+-----------+-----+----+------+\n",
      "|          0|    0|  73|     0|\n",
      "+-----------+-----+----+------+\n",
      "\n",
      "+-----------+-----+------+----+\n",
      "|nominations|title|awards|year|\n",
      "+-----------+-----+------+----+\n",
      "|          0|    0|     0|   0|\n",
      "+-----------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfawards.select([count(when(col(c).isNull(), c)).alias(c) for c in dfawards.columns]).show()\n",
    "dfawards2.select([count(when(col(c).isNull(), c)).alias(c) for c in dfawards2.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------------------+----+------+\n",
      "|nominations|title                                   |year|awards|\n",
      "+-----------+----------------------------------------+----+------+\n",
      "|1          |Joker   2019                            |null|1.0   |\n",
      "|0          |Once Upon a Time in Hollywood   2019    |null|1.0   |\n",
      "|0          |1917    2019                            |null|1.0   |\n",
      "|0          |Roma    2018                            |null|1.0   |\n",
      "|0          |The Favourite   2018                    |null|1.0   |\n",
      "+-----------+----------------------------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show records with year is NaN\n",
    "dfawards.filter(dfawards.year.isNull()).show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+\n",
      "|nominations|   title|awards|year|\n",
      "+-----------+--------+------+----+\n",
      "|         11|Joker   |   2.0|1970|\n",
      "+-----------+--------+------+----+\n",
      "\n",
      "+-----------+--------------------+------+----+\n",
      "|nominations|               title|awards|year|\n",
      "+-----------+--------------------+------+----+\n",
      "|         10|Once Upon a Time ...|   2.0|1970|\n",
      "+-----------+--------------------+------+----+\n",
      "\n",
      "+-----------+--------+------+----+\n",
      "|nominations|   title|awards|year|\n",
      "+-----------+--------+------+----+\n",
      "|         10|1917    |   3.0|1970|\n",
      "+-----------+--------+------+----+\n",
      "\n",
      "+-----------+--------+------+----+\n",
      "|nominations|   title|awards|year|\n",
      "+-----------+--------+------+----+\n",
      "|         10|Roma    |   3.0|1970|\n",
      "+-----------+--------+------+----+\n",
      "\n",
      "+-----------+----------------+------+----+\n",
      "|nominations|           title|awards|year|\n",
      "+-----------+----------------+------+----+\n",
      "|         10|The Favourite   |   1.0|1970|\n",
      "+-----------+----------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check records in dfmovies2\n",
    "dfawards2.filter(trim(dfawards2.title) == \"Joker\").show()\n",
    "dfawards2.filter(trim(dfawards2.title) == \"Once Upon a Time in Hollywood\").show()\n",
    "dfawards2.filter(trim(dfawards2.title) == \"1917\").show()\n",
    "dfawards2.filter(trim(dfawards2.title) == \"Roma\").show()\n",
    "dfawards2.filter(trim(dfawards2.title) == \"The Favourite\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop records with year == NaN\n",
    "dfawards = dfawards.dropna(subset=[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+----+------+\n",
      "|nominations|title|year|awards|\n",
      "+-----------+-----+----+------+\n",
      "|          0|    0|   0|     0|\n",
      "+-----------+-----+----+------+\n",
      "\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|nominations|title                                                   |year|awards|\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "|6          |Parasite                                                |2019|4.0   |\n",
      "|4          |Ford v Ferrari                                          |2019|2.0   |\n",
      "|1          |Learning to Skateboard in a Warzone (If You're a Girl)  |2019|1.0   |\n",
      "|1          |The Neighbors' Window                                   |2019|1.0   |\n",
      "|6          |Little Women                                            |2019|1.0   |\n",
      "+-----------+--------------------------------------------------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1243"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards.select([count(when(col(c).isNull(), c)).alias(c) for c in dfawards.columns]).show()\n",
    "dfawards.show(5, truncate = False)\n",
    "dfawards.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------------+------+------+\n",
      "|nominations|title                           |year  |awards|\n",
      "+-----------+--------------------------------+------+------+\n",
      "|1          |The Neighbors' Window           |2019.0|1.0   |\n",
      "|3          |Alice in Wonderland             |2010.0|2.0   |\n",
      "|1          |Happy Feet                      |2006.0|1.0   |\n",
      "|1          |Karl Hess: Toward Liberty       |1980.0|1.0   |\n",
      "|13         |Who's Afraid of Virginia Woolf? |1966.0|5.0   |\n",
      "+-----------+--------------------------------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# union dfawards and dfawards2, and remove duplicates (actually no duplicates in there two dataset)\n",
    "dfawards3 = dfawards.union(dfawards2).distinct()\n",
    "dfawards3.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1243"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### How to deal with null values\n",
    "#### 1. Deleting Rows \n",
    "This method commonly used to handle the null values. Here, we either delete a particular row if it has a null value for a particular feature and a particular column if it has more than 70-75% of missing values. This method is advised only when there are enough samples in the data set. \n",
    "#### 2. Replacing With Mean/Median/Mode  \n",
    "This strategy can be applied on a feature which has numeric data like the age of a person or the rating score. We can calculate the mean, median or mode of the feature and replace it with the missing values. This is an approximation which can add variance to the data set. \n",
    "#### 3. Assigning An Unique Category  \n",
    "A categorical feature will have a definite number of possibilities, such as gender, for example. Since they have a definite number of classes, we can assign another class for the missing values like unknown.\n",
    "#### 4. Predicting The Missing Values  \n",
    "Using the features which do not have missing values, we can predict the nulls with the help of a machine learning algorithm. \n",
    "#### 5. Using Algorithms Which Support Missing Values  \n",
    "KNN is a machine learning algorithm which works on the principle of distance measure. This algorithm can be used when there are nulls present in the dataset. While the algorithm is applied, KNN considers the missing values by taking the majority of the K nearest values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicate data, also confirm the dataset is on which level\n",
    "dfmovies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmovies[['movieId']].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfratings is on movieid and userid level\n",
    "dfratings[['movieId', 'userId']].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfawards3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfawards3 is on title and year level\n",
    "dfawards3[['title', 'year']].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9742 movies in the movies dataset\n"
     ]
    }
   ],
   "source": [
    "# basic count\n",
    "# number of movies in the dataset\n",
    "distinct_movie = dfmovies.select(\"movieId\").distinct().count()\n",
    "print('{} movies in the movies dataset'.format(distinct_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 users rated the movies\n"
     ]
    }
   ],
   "source": [
    "# number of users in the dataset\n",
    "distinct_user = dfratings.select(\"userId\").distinct().count()\n",
    "print('{} users rated the movies'.format(distinct_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 movies received awards\n"
     ]
    }
   ],
   "source": [
    "# number of movies receiving awards\n",
    "distinct_award = dfawards3.select(\"title\").distinct().count()\n",
    "print('{} movies received awards'.format(distinct_award))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the users that rated movies and the movies that were rated:\n",
      "Minimum number of ratings per user is 20\n",
      "Minimum number of ratings per movie is 1\n"
     ]
    }
   ],
   "source": [
    "# Minimum number of ratings per user\n",
    "# Minimum number of ratings per movie \n",
    "tmp1 = dfratings.groupBy(\"userID\").count().toPandas()['count'].min()\n",
    "tmp2 = dfratings.groupBy(\"movieId\").count().toPandas()['count'].min()\n",
    "print('For the users that rated movies and the movies that were rated:')\n",
    "print('Minimum number of ratings per user is {}'.format(tmp1))\n",
    "print('Minimum number of ratings per movie is {}'.format(tmp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3446 out of 9724 movies are rated by only one user\n"
     ]
    }
   ],
   "source": [
    "# number of movies rated by only one user\n",
    "tmp1 = sum(dfratings.groupBy(\"movieId\").count().toPandas()['count'] == 1)\n",
    "tmp2 = dfratings.select('movieId').distinct().count()\n",
    "print('{} out of {} movies are rated by only one user'.format(tmp1, tmp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check the dates in the ratings dataset\n",
    "tmp1 = dfratings['rate_time'].min()\n",
    "tmp2 = dfratings['rate_time'].max()\n",
    "print('ratings were made during {} and {}'.format(tmp1, tmp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split the mixed genres by '|'\n",
    "dfmovies2 = dfmovies.withColumn('genre', explode(split(dfmovies.genres, '\\|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfmovies2.show(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[genre: string, title: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the dataframe dfmovies2 produced to match every movie to a single genre\n",
    "genre_movies = dfmovies2 \\\n",
    "                    .groupBy(dfmovies2.genre) \\\n",
    "                    .agg(concat_ws(',', collect_list(dfmovies2.title)) \\\n",
    "                    .alias('title')) \\\n",
    "                    .orderBy('genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# use the dataframe dfmovies2 produced to count movie in a single genre\n",
    "genre_movies = dfmovies2 \\\n",
    "                    .groupBy(dfmovies2.genre) \\\n",
    "                    .sum(dfmovies2.title) \\\n",
    "                    .alias('count')) \\\n",
    "                    .orderBy('genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|             genre|               title|\n",
      "+------------------+--------------------+\n",
      "|(no genres listed)|La cravate (1957)...|\n",
      "|            Action|Heat (1995),Sudde...|\n",
      "|         Adventure|Toy Story (1995),...|\n",
      "|         Animation|Toy Story (1995),...|\n",
      "|          Children|Toy Story (1995),...|\n",
      "|            Comedy|Toy Story (1995),...|\n",
      "|             Crime|Heat (1995),Casin...|\n",
      "|       Documentary|Nico Icon (1995),...|\n",
      "|             Drama|Waiting to Exhale...|\n",
      "|           Fantasy|Toy Story (1995),...|\n",
      "|         Film-Noir|Devil in a Blue D...|\n",
      "|            Horror|Dracula: Dead and...|\n",
      "|              IMAX|Apollo 13 (1995),...|\n",
      "|           Musical|Pocahontas (1995)...|\n",
      "|           Mystery|Copycat (1995),Ci...|\n",
      "|           Romance|Grumpier Old Men ...|\n",
      "|            Sci-Fi|Powder (1995),Cit...|\n",
      "|          Thriller|Heat (1995),Golde...|\n",
      "|               War|Richard III (1995...|\n",
      "|           Western|Desperado (1995),...|\n",
      "+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[genre: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick distinct genre\n",
    "genres_dummies = dfmovies2.filter(dfmovies2.genre != '(no genres listed)') \\\n",
    "                     .select(dfmovies2.genre).distinct() \\\n",
    "                     .orderBy(dfmovies2.genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      genre|\n",
      "+-----------+\n",
      "|     Action|\n",
      "|  Adventure|\n",
      "|  Animation|\n",
      "|   Children|\n",
      "|     Comedy|\n",
      "|      Crime|\n",
      "|Documentary|\n",
      "|      Drama|\n",
      "|    Fantasy|\n",
      "|  Film-Noir|\n",
      "|     Horror|\n",
      "|       IMAX|\n",
      "|    Musical|\n",
      "|    Mystery|\n",
      "|    Romance|\n",
      "|     Sci-Fi|\n",
      "|   Thriller|\n",
      "|        War|\n",
      "|    Western|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres_dummies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Wrangling with Spark SQL and OLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfratings.createOrReplaceTempView(\"ratings\")     #userid, movieid, rating, timestamp\n",
    "dfmovies.createOrReplaceTempView(\"movies\")       #movieid, title, genres\n",
    "dflinks.createOrReplaceTempView(\"links\")         #movieid, imdbId, tmdbId\n",
    "dftags.createOrReplaceTempView(\"tags\")           #userid, movieid, tag, timestamp\n",
    "dfawards.createOrReplaceTempView(\"awards\")       #title, year, awards, nominations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split title and release year in separate columns in movies dataframe. Convert year to timestamp.       \n",
    "movies = spark.sql(\"select movieId, substr(title, 0, length(title)-7) as title, substr(title, -5, 4) as year from movies\")\n",
    "movies.show()\n",
    "movies.createOrReplaceTempView(\"movies\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of movies not rated\n",
    "spark.sql(\"\"\"select \n",
    "          count(distinct movies.movieId)\n",
    "          from movies \n",
    "          where movies.movieId not in\n",
    "          (select distinct ratings.movieId from ratings)\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the top 5 movies with high ratings\n",
    "spark.sql(\"\"\"select distinct\n",
    "    m.title as title,\n",
    "    avg(r.rating) as avg_rating\n",
    "    from movies as m join ratings as r on m.movieId = r.movieId\n",
    "    group by m.title\n",
    "    order by avg_rating desc\n",
    "    limit 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the most awards a movie got\n",
    "spark.sql(\"\"\"select distinct\n",
    "                    title,\n",
    "                    sum(awards) as tot_awards\n",
    "                    from awards\n",
    "                    group by title\n",
    "                    order by tot_awards desc\n",
    "                    limit 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the rating score of movie with highest awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# year of awards in the dataset\n",
    "spark.sql(\"\"\"select \n",
    "             min(year) as min_year,\n",
    "             max(year) as max_year\n",
    "             from awards\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# STEP 3: Connect to the Redshift Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Part 1: Extract data and transform into fact and dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                     )\n",
    "\n",
    "s3bucket =  s3.Bucket(\"udacity-input\") # private\n",
    "\n",
    "s3_data = iter(s3bucket.objects.filter(Prefix=\"ml-latest-small\"))\n",
    "for _ in range(5): print(next(s3_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.ci2m6m74tbzm.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS dimDate\n",
    "CREATE TABLE dimDate\n",
    "(\n",
    "  date_key timestamp NOT NULL PRIMARY KEY,\n",
    "  year smallint NOT NULL,\n",
    "  month smallint NOT NULL,\n",
    "  day smallint NOT NULL,\n",
    "  week smallint NOT NULL,\n",
    "  weekday varchar(3) NOT NULL\n",
    ");\n",
    "\n",
    "DROP TABLE IF EXISTS dimRating\n",
    "CREATE TABLE dimRating\n",
    "(\n",
    "  userId             smallint NOT NULL PRIMARY KEY,\n",
    "  movieId            smallint NOT NULL,\n",
    "  rating             numeric NOT NULL,\n",
    "  rate_time          timestamp REFERENCES dimdate (date_key)\n",
    ");\n",
    "\n",
    "DROP TABLE IF EXISTS dimGenres\n",
    "CREATE TABLE dimGenres\n",
    "(\n",
    "  genreId            smallint NOT NULL PRIMARY KEY\n",
    "  genres             text NOT NULL,\n",
    "  title              varchar(45) NOT NULL\n",
    ");\n",
    "\n",
    "DROP TABLE IF EXISTS factMovies\n",
    "CREATE TABLE factMovies\n",
    "(\n",
    "  MovieId      smallint NOT NULL PRIMARY KEY,\n",
    "  title        varchar(45) NOT NULL,\n",
    "  release_year year NOT NULL,\n",
    "  awards       smallint NOT NULL,\n",
    "  Nominations  smallint NOT NULL\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO dimDate (date_key, date, year, month, day, week, dow)\n",
    "SELECT DISTINCT(TO_CHAR(timestamp :: DATE, 'yyyyMMDD')::integer) AS date_key,\n",
    "       date(timestamp)                                           AS date,\n",
    "       EXTRACT(year FROM timestamp)                              AS year,\n",
    "       EXTRACT(month FROM timestamp)                             AS month,\n",
    "       EXTRACT(day FROM timestamp)                               AS day,\n",
    "       EXTRACT(week FROM timestamp)                              AS week,\n",
    "       dayofweek(timestamp)                                      AS dow\n",
    "FROM ratings;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO factMovies (movieId, title, release_year, awards, nominations)\n",
    "SELECT DISTINCT(movieId)                                         AS movieId,\n",
    "       title                                                     AS title,\n",
    "       year                                                      AS release_year,\n",
    "       awards                                                    AS awards,\n",
    "       nominations                                               AS nominations\n",
    "FROM movies as m LEFT JOIN awards as a on upper(trim(m.title)) = upper(trim(a.title));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO dimRatings (userId, movieId, rating, rate_time)\n",
    "SELECT * FROM ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO dimGenres (genreId, genre, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_field = [\"title\", \"duration\", \"year\", \"artist_id\"]\n",
    "songs_table = df.select(song_field).dropDuplicates().withColumn(\"song_id\", F.monotonically_increasing_id()).filter(~col(\"year\").isin([0]) & col(\"year\").isNotNull() & col(\"artist_id\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artist_field = [\"artist_id\", \"artist_name\", \"artist_location\", \"artist_latitude\", \"artist_longitude\"]\n",
    "artists_table = df.select(artist_field).dropDuplicates().dropna(subset=[\"artist_id\",\"artist_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table.write.partitionBy(\"year\", \"artist_id\").parquet(\"s3a://sparkifytest/songs/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_table.write.parquet(\"s3a://sparkifytest/artists/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "user_field = [\" userId as user_id\", \"firstName as first_name\", \"lastName as last_name\", \"gender\", \"level\"]\n",
    "users_table = df.selectExpr(user_field).dropDuplicates().dropna(how = \"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.write.parquet(\"s3a://sparkifytest/users/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.write.partitionBy(\"year\", \"month\").parquet(\"s3a://sparkifytest/time/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.write.parquet(\"s3a://sparkifytest/users/\", mode=\"overwrite\")\n",
    "song_df = spark.read.parquet(\"s3a://sparkifytest/songs/*/*/*\")\n",
    "artist_df = spark.read.parquet(\"s3a://sparkifytest/artists/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "Join_song = df.join(song_df, ((song_df.title == df.song) & (song_df.duration == df.length)))\n",
    "artists_songs_logs = Join_song.join(artist_df, (Join_song.artist == artist_df.artist_name))\n",
    "songplays = artists_songs_logs.join(time_table, (artists_songs_logs.start_time == time_table.start_time), 'left').drop(artists_songs_logs.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_field = [\"start_time\", \"userId as user_id\", \"level\", \"song_id\", \"artist_id\", \"sessionid as session_id\", \"artist_location as location\", \"userAgent as user_agent\", \"year\", \"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table = songplays.selectExpr(songplays_field).dropDuplicates().dropna(subset=[\"user_id\", \"artist_id\", \\\n",
    "\"song_id\"]).withColumn(\"songplay_id\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.write.partitionBy(\"year\", \"month\").parquet(output_date + \"songplays/\", mode=\"overwrite\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.createOrReplaceTempView(\"songplays\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT month, count(song_id) as song_num\n",
    "    FROM songplays\n",
    "    GROUP by month\n",
    "    order by song_num desc\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
